# Adversarial Chatbot Testing Guide

## Overview

Adversarial testing enables automated bot-to-bot conversations where an AI-powered "adversarial bot" tests your target chatbot through realistic, challenging interactions. This approach provides:

- **Automated stress testing** without manual scripting
- **Diverse conversation scenarios** generated by LLMs
- **Edge case discovery** through adversarial strategies
- **Continuous multi-turn testing** with adaptive responses
- **Comprehensive logging** and validation

## Quick Start

### 1. With Ollama (Local, Free)

```bash
# Install Ollama
# Visit https://ollama.ai for installation instructions

# Pull a model
ollama pull llama2

# Start Ollama
ollama serve

# Run adversarial tests
patience adversarial --target http://localhost:3000/chat --adversary ollama
```

### 2. With OpenAI (GPT-4)

```bash
# Set your API key in the config file
# Edit examples/adversarial-openai-config.json

# Run tests
patience adversarial --config examples/adversarial-openai-config.json
```

### 3. With Anthropic (Claude)

```bash
# Set your API key in the config file
# Edit examples/adversarial-anthropic-config.json

# Run tests
patience adversarial --config examples/adversarial-anthropic-config.json
```

## LLM Providers

### Ollama (Recommended for Development)

**Pros:**
- ‚úÖ Free and runs locally
- ‚úÖ No API key required
- ‚úÖ Privacy - data stays on your machine
- ‚úÖ No rate limits or costs
- ‚úÖ Multiple models available (llama2, mistral, etc.)

**Cons:**
- ‚ö†Ô∏è Requires local installation
- ‚ö†Ô∏è May be slower than cloud APIs
- ‚ö†Ô∏è Quality depends on model size

**Setup:**
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull a model
ollama pull llama2        # 7B model, good balance
ollama pull mistral       # Alternative
ollama pull llama2:13b    # Larger, better quality

# Start server
ollama serve
```

**Configuration:**
```json
{
  "adversarialBot": {
    "provider": "ollama",
    "model": "llama2",
    "endpoint": "http://localhost:11434",
    "temperature": 0.7
  }
}
```

### OpenAI (GPT-4, GPT-3.5)

**Pros:**
- ‚úÖ High-quality responses
- ‚úÖ Fast and reliable
- ‚úÖ Multiple model options
- ‚úÖ Good for production testing

**Cons:**
- üí∞ Costs money per API call
- üîë Requires API key
- üìä Rate limits apply

**Setup:**
1. Get API key from https://platform.openai.com/api-keys
2. Add to configuration file

**Configuration:**
```json
{
  "adversarialBot": {
    "provider": "openai",
    "model": "gpt-4",
    "apiKey": "sk-...",
    "temperature": 0.7,
    "maxTokens": 500
  }
}
```

**Models:**
- `gpt-4` - Best quality, most expensive
- `gpt-4-turbo` - Faster, cheaper than GPT-4
- `gpt-3.5-turbo` - Fast and cheap, good quality

**Estimated Costs:**
- GPT-4: ~$0.03 per 1K tokens (~$0.01 per conversation)
- GPT-3.5-turbo: ~$0.002 per 1K tokens (~$0.001 per conversation)

### Anthropic (Claude)

**Pros:**
- ‚úÖ Excellent reasoning and analysis
- ‚úÖ Long context window
- ‚úÖ Good at following complex instructions
- ‚úÖ Thoughtful and nuanced responses

**Cons:**
- üí∞ Costs money per API call
- üîë Requires API key
- üìä Rate limits apply

**Setup:**
1. Get API key from https://console.anthropic.com/
2. Add to configuration file

**Configuration:**
```json
{
  "adversarialBot": {
    "provider": "anthropic",
    "model": "claude-3-sonnet-20240229",
    "apiKey": "sk-ant-...",
    "temperature": 0.7,
    "maxTokens": 1024
  }
}
```

**Models:**
- `claude-3-opus-20240229` - Most capable, most expensive
- `claude-3-sonnet-20240229` - Balanced performance and cost
- `claude-3-haiku-20240307` - Fast and affordable

**Estimated Costs:**
- Claude 3 Opus: ~$0.015 per 1K tokens
- Claude 3 Sonnet: ~$0.003 per 1K tokens
- Claude 3 Haiku: ~$0.00025 per 1K tokens

## Testing Strategies

### 1. Exploratory Strategy

**Purpose:** Map the bot's capabilities through diverse, realistic questions.

**Best for:**
- Initial testing of new bots
- Understanding feature coverage
- Baseline quality assessment

**Example:**
```bash
patience adversarial \
  --target http://localhost:3000/chat \
  --strategy exploratory \
  --turns 15 \
  --conversations 5
```

**What it does:**
- Asks varied questions across different topics
- Tests different conversation styles
- Explores knowledge boundaries
- Natural, human-like interactions

### 2. Adversarial Strategy

**Purpose:** Find weaknesses through edge cases and challenging inputs.

**Best for:**
- Security testing
- Error handling validation
- Robustness assessment
- Finding edge cases

**Example:**
```bash
patience adversarial \
  --target http://localhost:3000/chat \
  --strategy adversarial \
  --turns 20 \
  --conversations 10
```

**What it does:**
- Asks ambiguous questions
- Tests contradictory statements
- Tries to confuse the bot
- Rapid topic changes
- Unusual input patterns

### 3. Focused Strategy

**Purpose:** Deep dive into specific features or domains.

**Best for:**
- Feature-specific testing
- Domain knowledge validation
- Regression testing
- Specialized capability assessment

**Example:**
```json
{
  "conversation": {
    "strategy": "focused",
    "goals": [
      "Test product recommendation capabilities",
      "Validate pricing information accuracy",
      "Test shopping cart functionality"
    ]
  }
}
```

**What it does:**
- Stays on specified topics
- Progressive complexity
- Tests depth of knowledge
- Verifies consistency

### 4. Stress Strategy

**Purpose:** Test performance under challenging conditions.

**Best for:**
- Load testing
- Context retention testing
- Complex scenario handling
- Performance validation

**Example:**
```bash
patience adversarial \
  --target http://localhost:3000/chat \
  --strategy stress \
  --turns 25 \
  --conversations 20
```

**What it does:**
- Rapid context switching
- Complex multi-part questions
- Long inputs
- References to earlier conversation
- High cognitive load

## Configuration Options

### Complete Configuration Example

```json
{
  "targetBot": {
    "name": "My Chatbot",
    "protocol": "http",
    "endpoint": "http://localhost:3000/chat",
    "authentication": {
      "type": "bearer",
      "credentials": "your-token"
    },
    "headers": {
      "X-Custom-Header": "value"
    }
  },
  "adversarialBot": {
    "provider": "ollama",
    "model": "llama2",
    "endpoint": "http://localhost:11434",
    "temperature": 0.7,
    "maxTokens": 500
  },
  "conversation": {
    "strategy": "exploratory",
    "maxTurns": 10,
    "startingPrompts": [
      "Hello! Can you help me?",
      "Hi there! What can you do?"
    ],
    "goals": [
      "Test greeting capabilities",
      "Explore knowledge boundaries"
    ],
    "timeout": 30000
  },
  "validation": {
    "rules": [
      {
        "type": "pattern",
        "expected": "help|assist|support",
        "description": "Bot should offer assistance"
      }
    ],
    "realTime": true
  },
  "execution": {
    "numConversations": 5,
    "concurrent": 2,
    "delayBetweenTurns": 1000,
    "delayBetweenConversations": 2000
  },
  "safety": {
    "maxCostUSD": 5.0,
    "maxRequestsPerMinute": 50,
    "contentFilter": true
  },
  "reporting": {
    "outputPath": "./adversarial-reports",
    "formats": ["json", "text", "csv"],
    "includeTranscripts": true,
    "realTimeMonitoring": true
  }
}
```

### Key Configuration Fields

**targetBot:**
- `protocol`: "http" or "websocket"
- `endpoint`: Your bot's API endpoint
- `authentication`: Optional auth configuration

**adversarialBot:**
- `provider`: "ollama", "openai", or "anthropic"
- `model`: Model name (provider-specific)
- `apiKey`: Required for OpenAI and Anthropic
- `temperature`: 0.0-1.0 (higher = more creative)
- `maxTokens`: Maximum response length

**conversation:**
- `strategy`: Testing approach
- `maxTurns`: Maximum conversation length
- `startingPrompts`: Optional conversation starters
- `goals`: Strategy-specific objectives

**validation:**
- `rules`: Validation rules to apply
- `realTime`: Validate during conversation

**execution:**
- `numConversations`: How many conversations to run
- `concurrent`: Parallel execution count
- `delayBetweenTurns`: Pause between messages (ms)

**safety:**
- `maxCostUSD`: Stop if cost exceeds this
- `maxRequestsPerMinute`: Rate limiting
- `contentFilter`: Enable content filtering

## CLI Usage

### Basic Commands

```bash
# Quick start with defaults
patience adversarial --target http://localhost:3000/chat

# Specify provider and model
patience adversarial \
  --target http://localhost:3000/chat \
  --adversary openai \
  --model gpt-4

# Use configuration file
patience adversarial --config my-config.json

# Override config file settings
patience adversarial \
  --config my-config.json \
  --turns 20 \
  --conversations 10
```

### Advanced Usage

```bash
# Run multiple strategies
for strategy in exploratory adversarial focused stress; do
  patience adversarial \
    --target http://localhost:3000/chat \
    --strategy $strategy \
    --output ./reports/$strategy
done

# Compare different models
for model in llama2 mistral; do
  patience adversarial \
    --target http://localhost:3000/chat \
    --model $model \
    --output ./reports/$model
done
```

## Output and Reports

### Report Formats

**JSON** - Structured data for programmatic analysis
```json
{
  "conversationId": "...",
  "messages": [...],
  "validationResults": [...],
  "metrics": {...}
}
```

**Text** - Human-readable transcripts
```
===========================================
Adversarial Conversation Log
===========================================
[10:30:00] ü§ñ Adversarial: Hello! Can you help me?
[10:30:02] üéØ Target: Of course! I'd be happy to help.
  [Validation: ‚úì PASS]
...
```

**CSV** - Tabular data for spreadsheet analysis
```csv
turn,role,timestamp,content,response_time_ms,validation_passed
1,adversarial,2025-01-15T10:30:00Z,"Hello!",,,
1,target,2025-01-15T10:30:02Z,"Hi there!",2000,true
```

### Analyzing Results

```bash
# View conversation transcripts
cat adversarial-reports/conversation-*.txt

# Analyze with existing tools
patience analyze adversarial-reports/conversation-*.json

# Export to spreadsheet
open adversarial-reports/conversation-*.csv
```

## Best Practices

### 1. Start with Ollama

Use Ollama for initial development and testing:
- No costs
- Fast iteration
- Privacy

### 2. Use Appropriate Strategies

- **Exploratory**: First-time testing, baseline
- **Adversarial**: Security, edge cases
- **Focused**: Feature-specific testing
- **Stress**: Performance, robustness

### 3. Set Cost Limits

Always set `maxCostUSD` when using paid APIs:
```json
{
  "safety": {
    "maxCostUSD": 5.0
  }
}
```

### 4. Monitor in Real-Time

Enable real-time monitoring during development:
```json
{
  "reporting": {
    "realTimeMonitoring": true
  }
}
```

### 5. Use Validation Rules

Define validation rules to automatically assess quality:
```json
{
  "validation": {
    "rules": [
      {
        "type": "pattern",
        "expected": "help|assist|support"
      }
    ],
    "realTime": true
  }
}
```

### 6. Run Multiple Conversations

Get better coverage with multiple conversations:
```bash
patience adversarial \
  --conversations 10 \
  --concurrent 2
```

## Troubleshooting

### Ollama Connection Issues

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama
ollama serve

# Check available models
ollama list
```

### OpenAI API Errors

- **401 Unauthorized**: Check API key
- **429 Rate Limit**: Reduce `concurrent` or add delays
- **404 Model Not Found**: Verify model name

### Anthropic API Errors

- **401 Unauthorized**: Check API key
- **429 Rate Limit**: Reduce request rate
- **400 Bad Request**: Check message format

### General Issues

- **Timeout**: Increase `conversation.timeout`
- **Memory**: Reduce `concurrent` conversations
- **Cost**: Set lower `maxCostUSD` limit

## Examples

See the `examples/` directory for complete configuration files:
- `adversarial-config.json` - Ollama configuration
- `adversarial-openai-config.json` - OpenAI configuration
- `adversarial-anthropic-config.json` - Anthropic configuration
